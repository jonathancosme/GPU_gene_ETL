{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eecab6-72f4-4b90-8825-4380d001fc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc76ff0-baa8-4961-b52a-f4f290f3224a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f44069-d264-49db-9ec4-91ee9517942e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714fb13-8a25-47ac-b472-c9b4ef1b1690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2bb36-4afb-47bd-a1c0-8b31e4775e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9a490-fb0b-4e33-8302-14e460296800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 15303. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 09:54:23,880 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#################\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask_cudf\n",
    "import argparse\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "# import os\n",
    "# import time\n",
    "\n",
    "def parse_opt(known=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--cfg', type=str, default='', help='path to .yaml file')\n",
    "    opt = parser.parse_known_args()[0] if known else parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "\n",
    "\n",
    "# load yaml file\n",
    "# opt = parse_opt()\n",
    "# print(f\"loading yaml file...\")\n",
    "# print(opt.cfg)\n",
    "config_yaml_data = yaml.safe_load(open('./make_dataset_configs/dataset_config_nclasses_1_size_500.yaml', 'r'))\n",
    "pprint(config_yaml_data)\n",
    "\n",
    "# set variables from yaml file\n",
    "train_data_path = config_yaml_data['train_data_path'] #\n",
    "val_data_path = config_yaml_data['val_data_path']  #\n",
    "test_data_path = config_yaml_data['test_data_path']  #\n",
    "unique_classes_data_path = config_yaml_data['unique_classes_data_path'] #\n",
    "number_of_classes = config_yaml_data['number_of_classes'] # the number of classes to randomly select\n",
    "size_per_class = config_yaml_data['size_per_class'] # the number of training examples to randomly select per class\n",
    "rand_seed = config_yaml_data['rand_seed'] # default is 42\n",
    "do_rand_seed = config_yaml_data['do_rand_seed'] # default is true\n",
    "tgt_col = config_yaml_data['tgt_col'] # column name of the labels in df\n",
    "inp_col = config_yaml_data['inp_col'] # column name of the inputs in df\n",
    "do_unknown_class = config_yaml_data['do_unknown_class'] # default is True\n",
    "name_for_unknown_class = config_yaml_data['name_for_unknown_class'] # default is _UNKOWN_\n",
    "train_data_split = config_yaml_data['train_data_split'] # proportion of data to use for training\n",
    "val_data_split = config_yaml_data['val_data_split'] # proportion of data to use for validation\n",
    "test_data_split = config_yaml_data['test_data_split'] # proportion of data to use for testing\n",
    "project_name = config_yaml_data['project_name'] # string\n",
    "output_data_path = config_yaml_data['output_data_path'] # string\n",
    "CUDA_VISIBLE_DEVICES = config_yaml_data['CUDA_VISIBLE_DEVICES']\n",
    "do_cuda_vis_dev = config_yaml_data['do_cuda_vis_dev']\n",
    "partition_size = config_yaml_data['partition_size']\n",
    "\n",
    "original_size_per_class = config_yaml_data['size_per_class']\n",
    "\n",
    "\n",
    "print(f\"train size per class: {size_per_class}\")\n",
    "# turn off random seed if needed\n",
    "if not do_rand_seed:\n",
    "    rand_seed = None\n",
    "\n",
    "print(f\"train size per class: {size_per_class}\")\n",
    "# turn off random seed if needed\n",
    "if not do_rand_seed:\n",
    "    rand_seed = None\n",
    "\n",
    "print(f\"starting Dask GPU cluster...\")\n",
    "if do_cuda_vis_dev:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol=\"ucx\",\n",
    "        enable_tcp_over_ucx=True,\n",
    "        CUDA_VISIBLE_DEVICES=CUDA_VISIBLE_DEVICES,\n",
    "    )\n",
    "else:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol=\"ucx\",\n",
    "        enable_tcp_over_ucx=True,\n",
    "    )\n",
    "client = Client(cluster)\n",
    "\n",
    "print(f\"loading classes file...\")\n",
    "# make all varaiables needed: number of samples from included df | outpath\n",
    "# select classes\n",
    "selected_classes = dask_cudf.read_csv(unique_classes_data_path, header=None, names=['classes'])[\n",
    "    'classes'].compute().to_numpy()\n",
    "total_classes = len(selected_classes)\n",
    "print(f\"randomly selecting {number_of_classes} of {total_classes} classes\")\n",
    "if do_rand_seed:\n",
    "    np.random.seed(rand_seed)\n",
    "selected_classes = np.random.choice(selected_classes, number_of_classes, replace=False)\n",
    "# calc number of samples to take\n",
    "# num_incl_samples = selected_classes.shape[0] * size_per_class\n",
    "# print(f\"number of samples to be taken: {num_incl_samples}\")\n",
    "original_selected_classes = selected_classes.copy()\n",
    "\n",
    "print(f\"creating folder name...\")\n",
    "# create output folder\n",
    "if do_unknown_class:\n",
    "    folder_name = f\"{project_name}_classes_{number_of_classes}_and_1_train_size_{original_size_per_class}\"\n",
    "else:\n",
    "    folder_name = f\"{project_name}_classes_{number_of_classes}_train_size_{original_size_per_class}\"\n",
    "out_folder_path = f\"{output_data_path}/{folder_name}\"\n",
    "print(f\"creating folder: {out_folder_path}\")\n",
    "Path(out_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def add_unknown_class(df):\n",
    "    bool_mask = df[tgt_col].isin(selected_classes)\n",
    "    df.loc[~bool_mask, tgt_col] = name_for_unknown_class\n",
    "    return df\n",
    "\n",
    "#### training data\n",
    "print(f\"loading in training data\")\n",
    "# load in df\n",
    "df = dask_cudf.read_parquet(train_data_path, partition_size=partition_size)\n",
    "\n",
    "if do_unknown_class:\n",
    "    print(f\"adding unknown class name to list\")\n",
    "    selected_classes = np.sort(np.append(name_for_unknown_class, selected_classes))\n",
    "    df = df.map_partitions(add_unknown_class)\n",
    "else:\n",
    "    print(f\"sorting selected class names\")\n",
    "    selected_classes = np.sort(selected_classes)\n",
    "\n",
    "print(f\"performing random selections per class...\")\n",
    "out_df = []\n",
    "selected_classes_str = ''\n",
    "total_classes = len(selected_classes)\n",
    "for cur_class_i, cur_class in enumerate(selected_classes):\n",
    "    # def get_class(df, cur_class):\n",
    "    #     return df[df[tgt_col] == cur_class]\n",
    "    print(f\"\\tclass {cur_class_i + 1} of {total_classes}: {cur_class}\")\n",
    "    # temp_ddf = df.map_partitions(get_class, cur_class).copy()  # sub set for our current class\n",
    "    temp_ddf = df[df[tgt_col] == cur_class].copy() \n",
    "    temp_row_cnt = len(temp_ddf)  # get the number of observations\n",
    "    cur_sample_amt = min([size_per_class, temp_row_cnt])\n",
    "    print(f\"\\ttarget sample size is {cur_sample_amt}\")\n",
    "    keep_frac = float(cur_sample_amt / temp_row_cnt)\n",
    "    temp_ddf = temp_ddf.sample(frac=keep_frac, replace=False, random_state=rand_seed)\n",
    "    out_df.append(temp_ddf.copy())\n",
    "    del temp_ddf\n",
    "    selected_classes_str += cur_class\n",
    "    selected_classes_str += '\\n'\n",
    "print(f\"concating dataframes...\")\n",
    "out_df = dask_cudf.concat(out_df).reset_index(True).repartition(partition_size=partition_size)\n",
    "del df\n",
    "\n",
    "print(f\"saving training output data...\")\n",
    "out_df.to_parquet(f\"{out_folder_path}/train_data.parquet\")\n",
    "\n",
    "print(f\"saving new classes file...\")\n",
    "open(f\"{out_folder_path}/class_names.csv\", 'w').write(selected_classes_str)\n",
    "\n",
    "print(f\"saving training classes count file...\")\n",
    "out_df_tgts = out_df[tgt_col].copy()\n",
    "del out_df\n",
    "out_df_tgts.value_counts().to_frame().to_csv(f\"{out_folder_path}/train_class_counts.csv\", header=False,\n",
    "                                             single_file=True)\n",
    "del out_df_tgts\n",
    "\n",
    "### val data\n",
    "selected_classes = original_selected_classes.copy()\n",
    "\n",
    "size_per_class = original_size_per_class\n",
    "size_per_class /= train_data_split\n",
    "size_per_class *= val_data_split\n",
    "size_per_class = int(round(size_per_class))\n",
    "\n",
    "print(f\"loading in val data\")\n",
    "# load in df\n",
    "df = dask_cudf.read_parquet(val_data_path, partition_size=partition_size)\n",
    "\n",
    "if do_unknown_class:\n",
    "    print(f\"adding unknown class name to list\")\n",
    "    selected_classes = np.sort(np.append(name_for_unknown_class, selected_classes))\n",
    "    df = df.map_partitions(add_unknown_class)\n",
    "else:\n",
    "    print(f\"sorting selected class names\")\n",
    "    selected_classes = np.sort(selected_classes)\n",
    "\n",
    "print(f\"performing random selections per class...\")\n",
    "out_df = []\n",
    "\n",
    "for cur_class_i, cur_class in enumerate(selected_classes):\n",
    "    # def get_class(df, cur_class):\n",
    "    #     return df[df[tgt_col] == cur_class]\n",
    "    print(f\"\\tclass {cur_class_i + 1} of {total_classes}: {cur_class}\")\n",
    "    # temp_ddf = df.map_partitions(get_class, cur_class).copy()  # sub set for our current class\n",
    "    temp_ddf = df[df[tgt_col] == cur_class].copy() \n",
    "    temp_row_cnt = len(temp_ddf)  # get the number of observations\n",
    "    cur_sample_amt = min([size_per_class, temp_row_cnt])\n",
    "    print(f\"\\ttarget sample size is {cur_sample_amt}\")\n",
    "    keep_frac = float(cur_sample_amt / temp_row_cnt)\n",
    "    temp_ddf = temp_ddf.sample(frac=keep_frac, replace=False, random_state=rand_seed)\n",
    "    out_df.append(temp_ddf.copy())\n",
    "    del temp_ddf\n",
    "print(f\"concating dataframes...\")\n",
    "out_df = dask_cudf.concat(out_df).reset_index(True).repartition(partition_size=partition_size)\n",
    "del df\n",
    "\n",
    "print(f\"saving val output data...\")\n",
    "out_df.to_parquet(f\"{out_folder_path}/val_data.parquet\")\n",
    "\n",
    "print(f\"saving val classes count file...\")\n",
    "out_df_tgts = out_df[tgt_col].copy()\n",
    "del out_df\n",
    "out_df_tgts.value_counts().to_frame().to_csv(f\"{out_folder_path}/val_class_counts.csv\", header=False,\n",
    "                                             single_file=True)\n",
    "del out_df_tgts\n",
    "\n",
    "### test data\n",
    "selected_classes = original_selected_classes.copy()\n",
    "\n",
    "size_per_class = original_size_per_class\n",
    "size_per_class /= train_data_split\n",
    "size_per_class *= test_data_split\n",
    "size_per_class = int(round(size_per_class))\n",
    "\n",
    "print(f\"loading in test data\")\n",
    "# load in df\n",
    "df = dask_cudf.read_parquet(test_data_path, partition_size=partition_size)\n",
    "\n",
    "if do_unknown_class:\n",
    "    print(f\"adding unknown class name to list\")\n",
    "    selected_classes = np.sort(np.append(name_for_unknown_class, selected_classes))\n",
    "    df = df.map_partitions(add_unknown_class)\n",
    "else:\n",
    "    print(f\"sorting selected class names\")\n",
    "    selected_classes = np.sort(selected_classes)\n",
    "\n",
    "print(f\"performing random selections per class...\")\n",
    "out_df = []\n",
    "\n",
    "for cur_class_i, cur_class in enumerate(selected_classes):\n",
    "    # def get_class(df, cur_class):\n",
    "    #     return df[df[tgt_col] == cur_class]\n",
    "    # print(f\"\\tclass {cur_class_i + 1} of {total_classes}: {cur_class}\")\n",
    "    # temp_ddf = df.map_partitions(get_class, cur_class).copy()  # sub set for our current class\n",
    "    temp_ddf = df[df[tgt_col] == cur_class].copy() \n",
    "    temp_row_cnt = len(temp_ddf)  # get the number of observations\n",
    "    cur_sample_amt = min([size_per_class, temp_row_cnt])\n",
    "    print(f\"\\ttarget sample size is {cur_sample_amt}\")\n",
    "    keep_frac = float(cur_sample_amt / temp_row_cnt)\n",
    "    temp_ddf = temp_ddf.sample(frac=keep_frac, replace=False, random_state=rand_seed)\n",
    "    out_df.append(temp_ddf.copy())\n",
    "    del temp_ddf\n",
    "print(f\"concating dataframes...\")\n",
    "out_df = dask_cudf.concat(out_df).reset_index(True).repartition(partition_size=partition_size)\n",
    "del df\n",
    "\n",
    "print(f\"saving test output data...\")\n",
    "out_df.to_parquet(f\"{out_folder_path}/test_data.parquet\")\n",
    "\n",
    "print(f\"saving test classes count file...\")\n",
    "out_df_tgts = out_df[tgt_col].copy()\n",
    "del out_df\n",
    "out_df_tgts.value_counts().to_frame().to_csv(f\"{out_folder_path}/test_class_counts.csv\", header=False,\n",
    "                                             single_file=True)\n",
    "del out_df_tgts\n",
    "\n",
    "print(f\"shutting down Dask client\")\n",
    "client.shutdown()\n",
    "client.close()\n",
    "print(f\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41cc7fbd-9c80-4af1-aeba-d9d76c939ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf4e9f6-eab8-49c6-a908-fc3bfbc739de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n"
     ]
    }
   ],
   "source": [
    "print(f\"performing random selections per class...\")\n",
    "out_df = []\n",
    "selected_classes_str = ''\n",
    "total_classes = len(selected_classes)\n",
    "for cur_class_i, cur_class in enumerate(selected_classes):\n",
    "    print(f\"\\tclass {cur_class_i + 1} of {total_classes}: {cur_class}\")\n",
    "    # temp_ddf = df.map_partitions(get_class, cur_class).copy()  # sub set for our current class\n",
    "    temp_ddf = df[df[tgt_col] == cur_class].copy() \n",
    "    temp_row_cnt = len(temp_ddf)  # get the number of observations\n",
    "    cur_sample_amt = min([size_per_class, temp_row_cnt])\n",
    "    print(f\"\\ttarget sample size is {cur_sample_amt}\")\n",
    "    keep_frac = float(cur_sample_amt / temp_row_cnt)\n",
    "    temp_ddf = temp_ddf.sample(frac=keep_frac, replace=False, random_state=rand_seed)\n",
    "    out_df.append(temp_ddf.copy())\n",
    "    del temp_ddf\n",
    "    selected_classes_str += cur_class\n",
    "    selected_classes_str += '\\n'\n",
    "print(f\"concating dataframes...\")\n",
    "out_df = dask_cudf.concat(out_df).reset_index(True).repartition(partition_size='100M')\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1afc6dd1-e45e-4f52-861b-63562bab7499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttarget sample size is 500\n"
     ]
    }
   ],
   "source": [
    "cur_class = 'MMP00713593'\n",
    "out_df = df.map_partitions(get_class, cur_class ).copy() # sub set for our current class\n",
    "temp_row_cnt = len(out_df)  # get the number of observations\n",
    "cur_sample_amt = min([size_per_class, temp_row_cnt])\n",
    "print(f\"\\ttarget sample size is {cur_sample_amt}\")\n",
    "keep_frac = float(cur_sample_amt / temp_row_cnt)\n",
    "out_df = out_df.sample(frac=keep_frac, replace=False, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7392a2ac-a6e7-48f6-9a2f-0c79c692d781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[C, T, C, T, C, C, A, C, T, G, G, C, A, T, C, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[G, A, A, C, G, T, C, C, T, G, G, T, T, T, T, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[C, C, A, T, T, T, T, A, T, C, T, A, A, C, G, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[A, G, G, C, C, G, A, T, G, C, T, T, A, T, G, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[G, G, A, C, G, G, T, A, A, A, G, T, C, T, A, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq     label\n",
       "2  [C, T, C, T, C, C, A, C, T, G, G, C, A, T, C, ...  _UNKOWN_\n",
       "3  [G, A, A, C, G, T, C, C, T, G, G, T, T, T, T, ...  _UNKOWN_\n",
       "4  [C, C, A, T, T, T, T, A, T, C, T, A, A, C, G, ...  _UNKOWN_\n",
       "5  [A, G, G, C, C, G, A, T, G, C, T, T, A, T, G, ...  _UNKOWN_\n",
       "0  [G, G, A, C, G, G, T, A, A, A, G, T, C, T, A, ...  _UNKOWN_"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d835cf67-6df6-44dd-a51c-d84af9d82ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f0ed8aa-a074-4746-b10a-de697dd2c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dask_cudf.read_parquet('test.parquet',partition_size='100M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffc3b761-0175-4982-b120-480b8920bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1737250</th>\n",
       "      <td>[G, G, A, C, G, G, T, A, A, A, G, T, C, T, A, ...</td>\n",
       "      <td>_UNKOWN_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       seq     label\n",
       "1737250  [G, G, A, C, G, G, T, A, A, A, G, T, C, T, A, ...  _UNKOWN_"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f16c038b-a05b-497a-8c3d-01a47f8d307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_UNKOWN_       12477163\n",
       "MMP00713593        8449\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[tgt_col].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483d99a-9dff-4f98-92e8-12b98a75451a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
