{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5badd5b5-54f8-4775-87b2-9540c737602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "fasta_to_parquet_config.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'base_col_names': ['seq', 'label'],\n",
      " 'clean_fasta_file': '/media/jcosme/bigdata/MarRef.parquet',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'fasta_sep': '>',\n",
      " 'partition_size': '100M',\n",
      " 'raw_fasta_file': '/media/jcosme/bigdata/MarRef.training.fasta'}\n",
      "starting Dask GPU cluster...\n",
      "reading .fasta file /media/jcosme/bigdata/MarRef.training.fasta\n",
      "shifting data...\n",
      "dropping empty rows...\n",
      "saving cleaned data to /media/jcosme/bigdata/MarRef.parquet\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda run -n dask python fasta_to_parquet.py --cfg fasta_to_parquet_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3daa41e2-a750-4fff-975d-2cad2c1705de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "convert_labels_to_species_config.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'in_file': '/media/jcosme/bigdata/MarRef.parquet',\n",
      " 'label_col_name': 'label',\n",
      " 'label_regex': '(?:[^a-zA-Z0-9]+)([a-zA-Z]+[0-9]+)(?:[^a-zA-Z0-9]+)',\n",
      " 'out_name': 'MarRef_species',\n",
      " 'output_dir': '/media/jcosme/bigdata',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME'}\n",
      "starting Dask GPU cluster...\n",
      "reading file /media/jcosme/bigdata/MarRef.parquet\n",
      "saving file /media/jcosme/bigdata/COSME/MarRef_species.parquet\n",
      "saving file /media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda run -n dask python convert_labels_to_species.py --cfg convert_labels_to_species_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69bc682f-49fb-4668-a50a-7ed9c9c0723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "make_kmers_config.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'base_col_names': ['seq', 'label'],\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'in_file': '/media/jcosme/bigdata/COSME/MarRef_species.parquet',\n",
      " 'input_col_name': 'seq',\n",
      " 'k_mer': 1,\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'out_name': 'MarRef_species_k_1',\n",
      " 'output_dir': '/media/jcosme/bigdata',\n",
      " 'partition_size': '100M',\n",
      " 'possible_gene_values': ['A', 'C', 'G', 'T'],\n",
      " 'project_name': 'COSME'}\n",
      "starting Dask GPU cluster...\n",
      "reading file /media/jcosme/bigdata/COSME/MarRef_species.parquet\n",
      "saving file /media/jcosme/bigdata/COSME/MarRef_species_k_1.parquet\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/dask/lib/python3.8/site-packages/cudf/core/column/string.py:968: UserWarning: `n` parameter is not supported when `pat` and `repl` are list-like inputs\n",
      "  warnings.warn(\n",
      "/home/jcosme/miniconda3/envs/dask/lib/python3.8/site-packages/cudf/core/column/string.py:968: UserWarning: `n` parameter is not supported when `pat` and `repl` are list-like inputs\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda run -n dask python make_kmers.py --cfg make_kmers_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c1b5dd-ec82-4e14-a34e-1347fe103cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "make_data_splits_config.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'in_file': '/media/jcosme/bigdata/COSME/MarRef_species_k_1.parquet',\n",
      " 'out_name': 'MarRef_species_k_1',\n",
      " 'output_dir': '/media/jcosme/bigdata',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'test_split': 0.08,\n",
      " 'train_split': 0.84,\n",
      " 'val_split': 0.08}\n",
      "starting Dask GPU cluster...\n",
      "reading file /media/jcosme/bigdata/COSME/MarRef_species_k_1.parquet\n",
      "splitting data...\n",
      "saving train file /media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet\n",
      "saving val file /media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet\n",
      "saving val file /media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda run -n dask python make_data_splits.py --cfg make_data_splits_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3633a-dcb2-4308-b79a-66dd693e22ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce86f97-d22d-434f-9650-53c99e589cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f47423f-832d-47dc-8917-e8142723b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_configs = yaml.safe_load(open('all_datasets_configs.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e9f4ba-306c-41af-9648-857dd6bc7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './make_dataset_configs'\n",
    "all_sizes = all_datasets_configs['all_sizes']\n",
    "all_sizes = sorted(all_sizes, reverse=True)\n",
    "all_n_classes = all_datasets_configs['all_n_classes']\n",
    "all_n_classes = sorted(all_n_classes, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613fb68a-9d0f-4370-8621-460b97502084",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_str = open('template_make_dataset_config.yaml', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76eb2a53-edb3-4e73-a38e-72c68eb3f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 93269. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 17:27:39,608 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 17:35:52,142 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #10791] ep: 0x7f3ea82582d0, tag: 0xf30db17476f9393b, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #10791] ep: 0x7f3ea82582d0, tag: 0xf30db17476f9393b, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_16_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 16,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 8000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 8000\n",
      "train size per class: 8000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 16 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_8000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 8000\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 8000\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 8000\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 8000\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 8000\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 8000\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 8000\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 8000\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 8000\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 8000\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 8000\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 8000\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 8000\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 8000\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 8000\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 8000\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 8000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 762\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 762\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 762\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 762\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 762\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 762\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 762\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 762\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 762\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 762\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 762\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 762\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 762\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 762\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 762\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 762\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 762\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 762\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 762\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 762\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 762\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 762\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 94199. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 17:35:59,061 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 17:44:10,927 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_16_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 16,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 4000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 4000\n",
      "train size per class: 4000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 16 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_4000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 4000\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 4000\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 4000\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 4000\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 4000\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 4000\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 4000\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 4000\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 4000\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 4000\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 4000\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 4000\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 4000\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 4000\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 4000\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 4000\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 4000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 381\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 381\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 381\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 381\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 381\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 381\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 381\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 381\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 381\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 381\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 381\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 381\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 381\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 381\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 381\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 381\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 381\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 381\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 381\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 381\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 381\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 381\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 95139. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 17:44:17,582 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 17:52:35,805 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_16_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 16,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 2000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 2000\n",
      "train size per class: 2000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 16 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_2000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 2000\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 2000\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 2000\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 2000\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 2000\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 2000\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 2000\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 2000\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 2000\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 2000\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 2000\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 2000\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 2000\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 2000\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 2000\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 2000\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 2000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 190\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 190\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 190\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 190\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 190\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 190\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 190\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 190\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 190\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 190\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 190\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 190\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 190\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 190\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 190\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 190\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 190\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 190\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 190\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 190\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 190\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 190\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 96204. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 17:52:43,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:00:59,352 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_16_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 16,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 1000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 1000\n",
      "train size per class: 1000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 16 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_1000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 1000\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 1000\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 1000\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 1000\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 1000\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 1000\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 1000\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 1000\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 1000\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 1000\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 1000\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 1000\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 1000\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 1000\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 1000\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 1000\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 1000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 95\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 95\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 95\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 95\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 95\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 95\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 95\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 95\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 95\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 95\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 95\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 95\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 95\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 95\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 95\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 95\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 95\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 95\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 95\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 95\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 95\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 95\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 97161. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:01:06,431 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:09:29,352 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #10824] ep: 0x7f7f5a4b02d0, tag: 0xd25eeeb47990b7a9, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #10824] ep: 0x7f7f5a4b02d0, tag: 0xd25eeeb47990b7a9, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_16_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 16,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 16 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 500\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 500\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 500\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 500\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 500\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 500\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 500\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 500\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 500\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 500\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 500\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 500\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 500\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 500\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 500\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 48\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 48\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 48\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 48\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 48\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 48\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 48\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 48\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 48\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 48\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 48\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 17: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 17: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 17: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 17: MMP03282272\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 17: MMP03380222\n",
      "\ttarget sample size is 48\n",
      "\tclass 6 of 17: MMP03701403\n",
      "\ttarget sample size is 48\n",
      "\tclass 7 of 17: MMP03737951\n",
      "\ttarget sample size is 48\n",
      "\tclass 8 of 17: MMP04487880\n",
      "\ttarget sample size is 48\n",
      "\tclass 9 of 17: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 10 of 17: MMP08222610\n",
      "\ttarget sample size is 48\n",
      "\tclass 11 of 17: MMP08634218\n",
      "\ttarget sample size is 48\n",
      "\tclass 12 of 17: MMP10144670\n",
      "\ttarget sample size is 48\n",
      "\tclass 13 of 17: MMP11104881\n",
      "\ttarget sample size is 48\n",
      "\tclass 14 of 17: MMP11164061\n",
      "\ttarget sample size is 48\n",
      "\tclass 15 of 17: MMP12491243\n",
      "\ttarget sample size is 48\n",
      "\tclass 16 of 17: MMP12860083\n",
      "\ttarget sample size is 48\n",
      "\tclass 17 of 17: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 98603. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:09:36,613 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:14:31,271 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #5727] ep: 0x7f74818e82d0, tag: 0x63c66b9da0e0fb64, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #5727] ep: 0x7f74818e82d0, tag: 0x63c66b9da0e0fb64, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_8_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 8,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 8000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 8000\n",
      "train size per class: 8000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 8 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_8000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 8000\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 8000\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 8000\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 8000\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 8000\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 8000\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 8000\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 8000\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 8000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 762\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 762\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 762\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 762\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 762\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 762\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 99298. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:14:38,308 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:19:34,425 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_8_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 8,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 4000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 4000\n",
      "train size per class: 4000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 8 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_4000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 4000\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 4000\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 4000\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 4000\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 4000\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 4000\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 4000\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 4000\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 4000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 381\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 381\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 381\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 381\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 381\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 381\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 99997. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:19:41,869 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:24:41,903 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_8_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 8,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 2000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 2000\n",
      "train size per class: 2000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 8 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_2000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 2000\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 2000\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 2000\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 2000\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 2000\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 2000\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 2000\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 2000\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 2000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 190\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 190\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 190\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 190\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 190\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 190\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 100688. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:24:49,309 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:29:44,048 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_8_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 8,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 1000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 1000\n",
      "train size per class: 1000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 8 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_1000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 1000\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 1000\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 1000\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 1000\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 1000\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 1000\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 1000\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 1000\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 1000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 95\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 95\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 95\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 95\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 95\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 95\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 101323. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:29:50,622 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:34:43,370 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #5718] ep: 0x7ff8a685f2d0, tag: 0x5421c8b71afd0c3e, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #5718] ep: 0x7ff8a685f2d0, tag: 0x5421c8b71afd0c3e, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_8_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 8,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 8 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 500\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 500\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 500\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 500\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 500\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 500\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 500\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 48\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 48\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 48\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 9: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 9: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 9: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 9: MMP03282272\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 9: MMP03380222\n",
      "\ttarget sample size is 48\n",
      "\tclass 6 of 9: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 7 of 9: MMP08634218\n",
      "\ttarget sample size is 48\n",
      "\tclass 8 of 9: MMP12491243\n",
      "\ttarget sample size is 48\n",
      "\tclass 9 of 9: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 101958. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:34:51,005 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:38:09,634 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_4_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 4,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 8000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 8000\n",
      "train size per class: 8000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 4 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_8000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 8000\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 8000\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 8000\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 8000\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 8000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 762\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 105138. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:38:17,235 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:41:32,303 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_4_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 4,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 4000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 4000\n",
      "train size per class: 4000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 4 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_4000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 4000\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 4000\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 4000\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 4000\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 4000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 381\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 110615. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:41:39,879 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:44:48,783 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_4_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 4,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 2000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 2000\n",
      "train size per class: 2000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 4 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_2000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 2000\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 2000\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 2000\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 2000\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 2000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 190\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 112431. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:44:56,326 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:48:10,836 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #3264] ep: 0x7f9e874ed2d0, tag: 0x37ced18254eb8de6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #3264] ep: 0x7f9e874ed2d0, tag: 0x37ced18254eb8de6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_4_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 4,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 1000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 1000\n",
      "train size per class: 1000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 4 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_1000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 1000\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 1000\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 1000\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 1000\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 1000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 95\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 113080. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:48:18,033 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:51:32,374 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_4_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 4,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 4 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 500\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 500\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 500\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 5: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 5: MMP02603922\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 5: MMP02604312\n",
      "\ttarget sample size is 48\n",
      "\tclass 4 of 5: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 5 of 5: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 113549. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:51:39,462 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:54:03,400 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1974] ep: 0x7f150b4ed2d0, tag: 0x3be28c4cc4bfcc67, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1974] ep: 0x7f150b4ed2d0, tag: 0x3be28c4cc4bfcc67, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_2_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 2,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 8000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 8000\n",
      "train size per class: 8000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 2 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_8000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 8000\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 8000\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 8000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 762\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 113923. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:54:10,413 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:56:33,730 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_2_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 2,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 4000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 4000\n",
      "train size per class: 4000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 2 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_4000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 4000\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 4000\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 4000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 381\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 114285. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:56:40,773 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 18:59:04,357 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_2_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 2,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 2000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 2000\n",
      "train size per class: 2000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 2 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_2000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 2000\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 2000\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 2000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 190\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 115750. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 18:59:11,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:01:34,640 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1980] ep: 0x7f8d69c452d0, tag: 0x776f11b95997acea, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1980] ep: 0x7f8d69c452d0, tag: 0x776f11b95997acea, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_2_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 2,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 1000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 1000\n",
      "train size per class: 1000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 2 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_1000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 1000\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 1000\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 1000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 95\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 116156. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:01:41,440 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:04:04,304 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_2_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 2,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 2 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 500\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 3: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 3: MMP05945920\n",
      "\ttarget sample size is 48\n",
      "\tclass 3 of 3: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 116601. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:04:11,474 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:06:09,475 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1329] ep: 0x7fab1e2d32d0, tag: 0x7f0e02fc54588eed, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1329] ep: 0x7fab1e2d32d0, tag: 0x7f0e02fc54588eed, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_1_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 8000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 8000\n",
      "train size per class: 8000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_8000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 8000\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 8000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 762\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 762\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 116960. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:06:16,274 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:08:13,653 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_1_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 4000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 4000\n",
      "train size per class: 4000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_4000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 4000\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 4000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 381\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 381\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 117303. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:08:20,689 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:10:18,622 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1329] ep: 0x7fbe086092d0, tag: 0x57992441f9d40de6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1329] ep: 0x7fbe086092d0, tag: 0x57992441f9d40de6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_1_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 2000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 2000\n",
      "train size per class: 2000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_2000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 2000\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 2000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 190\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 190\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 117639. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:10:25,334 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:12:21,178 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_1_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 1000,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 1000\n",
      "train size per class: 1000\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_1000\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 1000\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 1000\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 95\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 95\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "loading yaml file...\n",
      "./make_dataset_configs/dataset_config_nclasses_1_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'do_rand_seed': True,\n",
      " 'do_unknown_class': True,\n",
      " 'inp_col': 'seq',\n",
      " 'name_for_unknown_class': '_UNKOWN_',\n",
      " 'number_of_classes': 1,\n",
      " 'output_data_path': '/media/jcosme/bigdata/COSME/datasets',\n",
      " 'partition_size': '100M',\n",
      " 'project_name': 'COSME',\n",
      " 'rand_seed': 42,\n",
      " 'size_per_class': 500,\n",
      " 'test_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_test.parquet',\n",
      " 'test_data_split': 0.08,\n",
      " 'tgt_col': 'label',\n",
      " 'train_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_train.parquet',\n",
      " 'train_data_split': 0.84,\n",
      " 'unique_classes_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_unq_labs.csv',\n",
      " 'val_data_path': '/media/jcosme/bigdata/COSME/MarRef_species_k_1_val.parquet',\n",
      " 'val_data_split': 0.08}\n",
      "train size per class: 500\n",
      "train size per class: 500\n",
      "starting Dask GPU cluster...\n",
      "loading classes file...\n",
      "randomly selecting 1 of 855 classes\n",
      "creating folder name...\n",
      "creating folder: /media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_500\n",
      "loading in training data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 500\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 500\n",
      "concating dataframes...\n",
      "saving training output data...\n",
      "saving new classes file...\n",
      "saving training classes count file...\n",
      "loading in val data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving val output data...\n",
      "saving val classes count file...\n",
      "loading in test data\n",
      "adding unknown class name to list\n",
      "performing random selections per class...\n",
      "\tclass 1 of 2: MMP00713593\n",
      "\ttarget sample size is 48\n",
      "\tclass 2 of 2: _UNKOWN_\n",
      "\ttarget sample size is 48\n",
      "concating dataframes...\n",
      "saving test output data...\n",
      "saving test classes count file...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 117946. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:12:27,842 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2022-07-04 19:14:23,842 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1332] ep: 0x7fd1be3582d0, tag: 0x853712c3549a00d5, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #1332] ep: 0x7fd1be3582d0, tag: 0x853712c3549a00d5, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_res = []\n",
    "for cur_n_classes in all_n_classes:\n",
    "    # print(f\"cur class: {cur_n_classes}\")\n",
    "    for cur_class_size in all_sizes:\n",
    "        # print(f\"\\tcur class size: {cur_class_size}\")\n",
    "        # print(f\"\\t\\tcur split: {cur_split}\")\n",
    "        cur_str = base_str\n",
    "        cur_str += f\"\\nnumber_of_classes: {cur_n_classes}\"\n",
    "        cur_str += f\"\\nsize_per_class: {cur_class_size}\"\n",
    "        outfile = f\"{base_dir}/dataset_config_nclasses_{cur_n_classes}_size_{cur_class_size}.yaml\"\n",
    "        open(outfile, 'w').write(cur_str)\n",
    "        res = subprocess.call(f\"conda run -n rapids python make_dataset.py --cfg {outfile}\", shell=True)\n",
    "        all_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6909f6f-7d9c-4111-92b8-ee276c53d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120217. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:30:54,410 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:00,920 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_8_and_1_train_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_8000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120378. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:08,389 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:14,225 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_1_and_1_train_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_8000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120583. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:21,373 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:26,976 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fa0e87242d0, tag: 0xb5f03851fecc7fb1, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fa0e87242d0, tag: 0xb5f03851fecc7fb1, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_8_and_1_train_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_500',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120692. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:34,277 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:39,972 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_1_and_1_train_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_2000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120815. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:46,693 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:52,659 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f64fc6c72d0, tag: 0xe2182c8cbf21dab6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f64fc6c72d0, tag: 0xe2182c8cbf21dab6, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_4_and_1_train_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_8000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 120924. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:31:59,444 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:04,802 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f924a5672d0, tag: 0x22e825470f2db3b0, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f924a5672d0, tag: 0x22e825470f2db3b0, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_1_and_1_train_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_1000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121033. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:11,799 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:17,713 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fd9b9e962d0, tag: 0x52c201670b03d85d, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fd9b9e962d0, tag: 0x52c201670b03d85d, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_16_and_1_train_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_2000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121143. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:24,406 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:30,936 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f399067d2d0, tag: 0x49f0060e01db1b77, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f399067d2d0, tag: 0x49f0060e01db1b77, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_16_and_1_train_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_8000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121268. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:37,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:43,994 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fc0e49f42d0, tag: 0x5b58a32cce3beadf, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fc0e49f42d0, tag: 0x5b58a32cce3beadf, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_16_and_1_train_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_1000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121386. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:51,262 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:32:57,152 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_8_and_1_train_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_4000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121492. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:04,496 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:10,217 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_8_and_1_train_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_1000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121640. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:17,183 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:23,108 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_2_and_1_train_size_8000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_8000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121756. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:29,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:35,548 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f3def4752d0, tag: 0x812d3efd0e798148, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f3def4752d0, tag: 0x812d3efd0e798148, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_2_and_1_train_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_1000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121872. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:42,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:47,466 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_1_and_1_train_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_500',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 121980. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:33:54,332 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:00,174 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_4_and_1_train_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_4000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122087. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:07,170 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:12,874 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_2_and_1_train_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_2000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122210. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:19,630 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:25,036 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_2_and_1_train_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_500',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122321. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:32,239 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:37,973 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f05076972d0, tag: 0xb513a372ec3390f2, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f05076972d0, tag: 0xb513a372ec3390f2, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_4_and_1_train_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_2000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122435. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:45,132 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:50,624 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f3e819262d0, tag: 0xded991d3b343b7af, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f3e819262d0, tag: 0xded991d3b343b7af, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_4_and_1_train_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_500',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122544. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:34:57,428 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:03,095 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f05087ce2d0, tag: 0xedd9287737c36ce1, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7f05087ce2d0, tag: 0xedd9287737c36ce1, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_2_and_1_train_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_2_and_1_train_size_4000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122670. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:09,833 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:15,912 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_16_and_1_train_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_4000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122796. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:22,853 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:28,565 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_1_and_1_train_size_4000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_1_and_1_train_size_4000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 122906. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:35,346 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:41,034 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7ff6171702d0, tag: 0x2fd3f8597bb17014, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7ff6171702d0, tag: 0x2fd3f8597bb17014, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_4_and_1_train_size_1000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_4_and_1_train_size_1000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 123014. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:47,830 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:35:53,724 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 466, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_16_and_1_train_size_500.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_16_and_1_train_size_500',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n",
      "loading yaml file...\n",
      "./make_nvtab_configs/COSME_classes_8_and_1_train_size_2000.yaml\n",
      "{'CUDA_VISIBLE_DEVICES': '0',\n",
      " 'do_cuda_vis_dev': True,\n",
      " 'input_col_name': 'seq',\n",
      " 'input_dir': '/media/jcosme/bigdata/COSME/datasets/COSME_classes_8_and_1_train_size_2000',\n",
      " 'label_col_name': 'label',\n",
      " 'max_seq_len': 150,\n",
      " 'row_group_size': 10000}\n",
      "starting Dask GPU cluster...\n",
      "creating pipeline...\n",
      "fitting nvtab workflow on training data...\n",
      "making nvtab dataset for training...\n",
      "making nvtab dataset for val...\n",
      "making nvtab dataset for test...\n",
      "shutting down Dask client\n",
      "finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py:58: UserWarning: A CUDA context for device 0 already exists on process ID 123122. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:36:00,925 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/merlin/core/utils.py:384: FutureWarning: The `client` argument is deprecated from Workflow and will be removed in a future version of NVTabular. By default, a global client in the same python context will be detected automatically, and `merlin.utils.set_dask_client` (as well as `Distributed` and `Serial`) can be used for explicit control.\n",
      "  warnings.warn(\n",
      "2022-07-04 19:36:06,796 - distributed.client - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fd1614242d0, tag: 0x4ebd11dfbe1dbf05, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 479, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 401, in connect\n",
      "    raise CommClosedError(\"Connection closed before handshake completed\")\n",
      "distributed.comm.core.CommClosedError: Connection closed before handshake completed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 301, in read\n",
      "    await self.ep.recv(msg)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/ucp/core.py\", line 725, in recv\n",
      "    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)\n",
      "ucp._libs.exceptions.UCXCanceled: <[Recv #036] ep: 0x7fd1614242d0, tag: 0x4ebd11dfbe1dbf05, nbytes: 16, type: <class 'numpy.ndarray'>>: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1406, in _handle_report\n",
      "    msgs = await self.scheduler_comm.comm.read()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/ucx.py\", line 319, in read\n",
      "    raise CommClosedError(\"Connection closed by writer\")\n",
      "distributed.comm.core.CommClosedError: Connection closed by writer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1414, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/utils.py\", line 761, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1225, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/client.py\", line 1255, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/site-packages/distributed/comm/core.py\", line 313, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/jcosme/miniconda3/envs/rapids/lib/python3.9/asyncio/tasks.py\", line 652, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = './make_nvtab_configs'\n",
    "dsets_list = yaml.safe_load(open('template_make_dataset_config.yaml', 'r'))['output_data_path']\n",
    "dsets_list = glob(f\"{dsets_list}/*\")\n",
    "all_res = []\n",
    "for cur_dset in dsets_list:\n",
    "    base_str = open('template_make_nvtab_data_config.yaml', 'r').read()\n",
    "    base_str += f\"\\ninput_dir: {cur_dset}\"\n",
    "    outfile = f\"{base_dir}/{cur_dset.split('/')[-1]}.yaml\"\n",
    "    open(outfile, 'w').write(base_str)\n",
    "    res = subprocess.call(f\"conda run -n rapids python make_nvtab_data.py --cfg {outfile}\", shell=True)\n",
    "    all_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d565884-0f9f-4660-98e7-3e6bcfaab597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = './make_dataset_configs/dataset_config_nclasses_1_size_500.yaml'\n",
    "# outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38d19334-14b5-4981-8bae-5198fbb49df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = subprocess.call(f\"conda run -n rapids python make_nvtab_data.py --cfg {outfile}\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d5349-13c3-4e56-9d88-7e50bba0730f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
